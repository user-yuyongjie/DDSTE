{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0-DataPreprocess","provenance":[{"file_id":"190xUK2LCeL1IJnJ6e0U06Qz946VdqCK-","timestamp":1592917225671}],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1sHedZsf9TRuh0CxeaFbsLBt8t0-OPDVj","authorship_tag":"ABX9TyPmmvjfvkpdi44ZIYSAE8hB"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"xEGXoSs9Bmbj"},"source":["import warnings\n","warnings.filterwarnings('ignore')\n","import os\n","import time\n","import glob\n","import pandas as pd\n","import numpy as np\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from collections import Counter\n","from sklearn.utils import shuffle\n","import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"214KZ25rB2fh","colab":{"base_uri":"https://localhost:8080/","height":578},"executionInfo":{"status":"ok","timestamp":1603698566925,"user_tz":-480,"elapsed":28518,"user":{"displayName":"Ashin Wang","photoUrl":"","userId":"14930375768213082665"}},"outputId":"ce034610-ada6-49bc-e5b4-80ec319baa3c"},"source":["path =r'/content/drive/My Drive/Colab Notebooks/IDS/data/selectdata2018/'\n","filenames = glob.glob(path + \"*.csv\")\n","dfs = []\n","for filename in filenames:\n","    dfs.append(pd.read_csv(filename, keep_default_na=True))\n","df = pd.concat(dfs)\n","print(df['Label'].value_counts())\n","print('-----------------------------------')\n","# Drop Inf, NaN\n","df = df.replace([np.inf, -np.inf], np.nan)\n","df = df.dropna()\n","# Drop Timestamp feature\n","df = df.drop(['Timestamp'], axis=1)\n","cols = df.columns[:-1]\n","\n","# Format\n","for col in cols:\n","    if str(df[col].dtype) == 'float64':\n","        df[col] = (df[col]).round(3)\n","    else: \n","        df[col] = df[col]\n","\n","# Drop duplicates\n","df = df.drop_duplicates(subset=cols,keep='last')\n","print(df['Label'].value_counts())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Benign                      758248\n","DDOS attack-HOIC            668461\n","DDoS attacks-LOIC-HTTP      576175\n","DoS attacks-Hulk            434883\n","Bot                         282310\n","Infilteration               161059\n","SSH-Bruteforce              117322\n","DoS attacks-GoldenEye        41455\n","FTP-BruteForce               39346\n","DoS attacks-SlowHTTPTest     21092\n","DoS attacks-Slowloris        10285\n","DDOS attack-LOIC-UDP          1730\n","Brute Force -Web               611\n","Brute Force -XSS               230\n","SQL Injection                   87\n","Name: Label, dtype: int64\n","-----------------------------------\n","Benign                      675369\n","DDoS attacks-LOIC-HTTP      575364\n","DDOS attack-HOIC            198861\n","DoS attacks-Hulk            145199\n","Bot                         144535\n","Infilteration               127244\n","SSH-Bruteforce               94048\n","DoS attacks-GoldenEye        41406\n","DoS attacks-Slowloris         9908\n","DDOS attack-LOIC-UDP          1730\n","Brute Force -Web               550\n","Brute Force -XSS               227\n","SQL Injection                   82\n","FTP-BruteForce                  46\n","DoS attacks-SlowHTTPTest         3\n","Name: Label, dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VusKjfWjCz2c"},"source":["# Add Check(-1) dimention\n","df['Check(-1) in Init Fwd Win Byts'] = df['Init Fwd Win Byts'].apply(lambda x: 1 if x ==-1  else 0)\n","df['Check(-1) in Init Bwd Win Byts'] = df['Init Bwd Win Byts'].apply(lambda x: 1 if x ==-1  else 0)\n","\n","cols = list(df)\n","# Insert Check(-1) Dimension\n","cols.insert(67, cols.pop(cols.index('Check(-1) in Init Fwd Win Byts')))\n","cols.insert(69, cols.pop(cols.index('Check(-1) in Init Bwd Win Byts')))\n","df = df.loc[:, cols]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-k90_nyhwZw","colab":{"base_uri":"https://localhost:8080/","height":544},"executionInfo":{"status":"ok","timestamp":1603698633641,"user_tz":-480,"elapsed":93835,"user":{"displayName":"Ashin Wang","photoUrl":"","userId":"14930375768213082665"}},"outputId":"c2bc3d67-147b-4ebe-d18f-d3beb6a0ad0e"},"source":["df_data =df\n","#random_state\n","rn = 62\n","\n","df_Benign = df_data[df_data['Label'].str.contains('Benign')]\n","df_Benign = df_Benign.sample(n=300000,random_state=rn)\n","\n","df_Bot = df_data[df_data['Label'].str.contains('Bot')]\n","df_Bot = df_Bot.sample(n=20000,random_state=rn)\n","\n","df_Infilteration = df_data[df_data['Label'].str.contains('Infilteration')]\n","#df_Infilteration = df_Infilteration.sample(n=20000,random_state=rn)\n","\n","df_SSH = df_data[df_data['Label'].str.contains('SSH-Bruteforce')]\n","df_SSH = df_SSH.sample(n=20000,random_state=rn)\n","\n","df_HTTP = df_data[df_data['Label'].str.contains('attacks-LOIC-HTTP')]\n","df_HTTP = df_HTTP.sample(n=20000,random_state=rn)\n","\n","df_Hulk = df_data[df_data['Label'].str.contains('Hulk')]\n","df_Hulk = df_Hulk.sample(n=20000,random_state=rn)\n","\n","df_HOIC = df_data[df_data['Label'].str.contains('HOIC')]\n","df_HOIC = df_HOIC.sample(n=20000,random_state=rn)\n","\n","df_GoldenEye = df_data[df_data['Label'].str.contains('GoldenEye')]\n","df_GoldenEye = df_GoldenEye.sample(n=20000,random_state=rn)\n","\n","df_FTP = df_data[df_data['Label'].str.contains('FTP')]\n","df_FTP = df_FTP[:]\n","\n","\n","df_Other = df_data[df_data['Label'].str.contains('Brute Force|attacks-Slowloris|attack-LOIC-UDP|SQL')]\n","\n","df = pd.concat([df_GoldenEye,df_Hulk,df_HOIC,df_Benign,df_Bot,df_Infilteration,df_SSH,df_FTP,df_HTTP,df_Other], ignore_index=True) \n","\n","x = df.iloc[:,:-1] # columns[0 - n]\n","y = df.iloc[:,-1] # columns[-1] \n","print(df['Label'].value_counts())\n","\n","enn = EditedNearestNeighbours(sampling_strategy=['Benign','Infilteration'],kind_sel='all', n_neighbors=3, n_jobs=-1)\n","\n","x_Sample, y_Sample = enn.fit_sample(x, y)\n","x_Sample = pd.DataFrame(x_Sample, columns=df.columns[:-1])\n","y_Sample = pd.DataFrame(y_Sample,columns=['Label'])\n","\n","x_Sample = x_Sample.reset_index()\n","y_Sample = y_Sample.reset_index()\n","\n","df = pd.concat([x_Sample,y_Sample], axis=1)\n","df = df.drop(['index'], axis=1)\n","\n","# Hard samples\n","print('---------------------------------------------------------------------------')\n","print(df['Label'].value_counts())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Benign                    300000\n","Infilteration             127244\n","SSH-Bruteforce             20000\n","DoS attacks-Hulk           20000\n","Bot                        20000\n","DDOS attack-HOIC           20000\n","DoS attacks-GoldenEye      20000\n","DDoS attacks-LOIC-HTTP     20000\n","DoS attacks-Slowloris       9908\n","DDOS attack-LOIC-UDP        1730\n","Brute Force -Web             550\n","Brute Force -XSS             227\n","SQL Injection                 82\n","FTP-BruteForce                46\n","Name: Label, dtype: int64\n","---------------------------------------------------------------------------\n","Benign                    195542\n","Infilteration              50978\n","SSH-Bruteforce             20000\n","DoS attacks-Hulk           20000\n","Bot                        20000\n","DDOS attack-HOIC           20000\n","DoS attacks-GoldenEye      20000\n","DDoS attacks-LOIC-HTTP     20000\n","DoS attacks-Slowloris       9908\n","DDOS attack-LOIC-UDP        1730\n","Brute Force -Web             550\n","Brute Force -XSS             227\n","SQL Injection                 82\n","FTP-BruteForce                46\n","Name: Label, dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Voteb2DKCjXI","colab":{"base_uri":"https://localhost:8080/","height":272},"executionInfo":{"status":"ok","timestamp":1603699281808,"user_tz":-480,"elapsed":5795,"user":{"displayName":"Ashin Wang","photoUrl":"","userId":"14930375768213082665"}},"outputId":"01efa86a-37e1-4dc5-8a78-e001f77f78d2"},"source":["#random_state\n","rn = 62\n","\n","df_Benign = df_data[df_data['Label'].str.contains('Benign')]\n","df_Benign = df_Benign.sample(n=40000,random_state=rn)\n","\n","df_Bot = df_data[df_data['Label'].str.contains('Bot')]\n","df_Bot = df_Bot.sample(n=20000,random_state=rn)\n","\n","df_Infilteration = df_data[df_data['Label'].str.contains('Infilteration')]\n","df_Infilteration = df_Infilteration.sample(n=20000,random_state=rn)\n","\n","df_SSH = df_data[df_data['Label'].str.contains('SSH-Bruteforce')]\n","df_SSH = df_SSH.sample(n=20000,random_state=rn)\n","\n","df_HTTP = df_data[df_data['Label'].str.contains('attacks-LOIC-HTTP')]\n","df_HTTP = df_HTTP.sample(n=20000,random_state=rn)\n","\n","df_Hulk = df_data[df_data['Label'].str.contains('Hulk')]\n","df_Hulk = df_Hulk.sample(n=20000,random_state=rn)\n","\n","df_HOIC = df_data[df_data['Label'].str.contains('HOIC')]\n","df_HOIC = df_HOIC.sample(n=20000,random_state=rn)\n","\n","df_GoldenEye = df_data[df_data['Label'].str.contains('GoldenEye')]\n","df_GoldenEye = df_GoldenEye.sample(n=20000,random_state=rn)\n","\n","df_FTP = df_data[df_data['Label'].str.contains('FTP')]\n","df_FTP = df_FTP[:]\n","\n","\n","df_Other = df_data[df_data['Label'].str.contains('Brute Force|attacks-Slowloris|attack-LOIC-UDP|SQL')]\n","\n","df_Select = pd.concat([df_GoldenEye,df_Hulk,df_HOIC,df_Benign,df_Bot,df_Infilteration,df_SSH,df_FTP,df_HTTP,df_Other], ignore_index=True) \n","\n","#Label code\n","label_code = {'Benign':0,\n","              \n","              'Bot':1,\n","\n","              'DDOS attack-LOIC-UDP':2,\n","              'DDOS attack-HOIC':3,\n","              'DDoS attacks-LOIC-HTTP':4,\n","\n","              'DoS attacks-GoldenEye':5,\n","              'DoS attacks-Hulk':6,\n","              'DoS attacks-Slowloris':7,\n","\n","              'SSH-Bruteforce':8,\n","              'FTP-BruteForce':9,\n","\n","              'Infilteration':10,\n","            \n","              'Brute Force -Web':11,      \n","              'Brute Force -XSS':12,\n","              'SQL Injection':13}\n","\n","df_Select['Label'] = [label_code[item] for item in df_Select['Label']]\n","\n","print(df_Select['Label'].value_counts())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0     40000\n","10    20000\n","8     20000\n","6     20000\n","5     20000\n","4     20000\n","3     20000\n","1     20000\n","7      9908\n","2      1730\n","11      550\n","12      227\n","13       82\n","9        46\n","Name: Label, dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PRKxqH3eDPJE","colab":{"base_uri":"https://localhost:8080/","height":561},"executionInfo":{"status":"ok","timestamp":1603699284567,"user_tz":-480,"elapsed":2588,"user":{"displayName":"Ashin Wang","photoUrl":"","userId":"14930375768213082665"}},"outputId":"a918b5df-b214-49dc-ce9a-f8cb79600257"},"source":["df_select_shuffle = shuffle(df_Select, random_state=rn)\n","# train_test_split(80%-->train, 20%-->test)\n","y = df_select_shuffle.iloc[:,-1]\n","train_df, test_df = train_test_split(df_select_shuffle, test_size = .20, random_state=rn,stratify=y)\n","print(\"Train Size = {} | Test Size = {} | Test is {}% of Dataset\".format(len(train_df),len(test_df), len(test_df)/len(df_Select)))\n","print(train_df['Label'].value_counts())\n","print('------------------------------------')\n","print(test_df['Label'].value_counts())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train Size = 154034 | Test Size = 38509 | Test is 0.20000207745802237% of Dataset\n","0     32000\n","10    16000\n","8     16000\n","6     16000\n","5     16000\n","4     16000\n","3     16000\n","1     16000\n","7      7926\n","2      1384\n","11      440\n","12      181\n","13       66\n","9        37\n","Name: Label, dtype: int64\n","------------------------------------\n","0     8000\n","10    4000\n","8     4000\n","6     4000\n","5     4000\n","4     4000\n","3     4000\n","1     4000\n","7     1982\n","2      346\n","11     110\n","12      46\n","13      16\n","9        9\n","Name: Label, dtype: int64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AixMBBMDdOQ-"},"source":["# Original "]},{"cell_type":"code","metadata":{"id":"HoldyVGYrveb"},"source":["# select samples training and testing \n","x_train = train_df.iloc[:,:-1]\n","y_train = train_df.iloc[:,-1]\n","x_test = test_df.iloc[:,:-1]\n","y_test = test_df.iloc[:,-1]\n","\n","\n","# Standardization\n","# fit x_train mean/std\n","scaler = preprocessing.StandardScaler().fit(x_train)\n","\n","# Standardization transform\n","x_train = pd.DataFrame(scaler.transform(x_train), columns=x_train.columns)\n","y_train = pd.DataFrame(y_train)\n","x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)\n","y_test = pd.DataFrame(y_test)\n","\n","# Saving  file\n","x_train.to_pickle('/content/drive/My Drive/Colab Notebooks/IDS/CIC-IDS2018/pkl/original_x_train.pkl')\n","y_train.to_pickle('/content/drive/My Drive/Colab Notebooks/IDS/CIC-IDS2018/pkl/original_y_train.pkl')\n","x_test.to_pickle('/content/drive/My Drive/Colab Notebooks/IDS/CIC-IDS2018/pkl/original_x_test.pkl')\n","y_test.to_pickle('/content/drive/My Drive/Colab Notebooks/IDS/CIC-IDS2018/pkl/original_y_test.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jwNuEMYYAHs7"},"source":["# DSSTE Sampling"]},{"cell_type":"code","metadata":{"id":"KoMgns9K6AJe"},"source":["import pandas as pd\n","import numpy as np\n","import math\n","import random\n","from collections import Counter\n","from sklearn.datasets import make_classification\n","from imblearn.under_sampling import ClusterCentroids\n","from imblearn.under_sampling import EditedNearestNeighbours\n","\n","def class_attribute(data, threshold, N):\n","    X, y = data.iloc[:,:-1], data.iloc[:,-1:]\n","    \n","    data_counter = Counter(data.iloc[:, -1])\n","    print(data_counter)\n","\n","    vcs = y.value_counts(normalize=True)\n","    print(vcs)\n","    \n","    minority_cls, majority_cls = [], []\n","    \n","    for idx, vc in zip(range(len(vcs)), vcs):\n","        if vc <= threshold:\n","            minority_cls.append(list(vcs.index[idx])[0])\n","        else:\n","            majority_cls.append(list(vcs.index[idx])[0])\n","    print('minority_cls: {}'.format(minority_cls), 'majority_cls: {}'.format(majority_cls))\n","    \n","    cc_value = []\n","    for cls in majority_cls:\n","        cc_value.append(data_counter[cls])\n","    cc_dict = dict(zip(majority_cls, cc_value))\n","    print(cc_dict)\n","\n","    ss_value = []\n","    for cls in minority_cls:\n","        ss_value.append(data_counter[cls])\n","    ss_dict = dict(zip(minority_cls, ss_value))\n","    print(ss_dict)\n","    return cc_dict, ss_dict\n","    \n","def get_difficult_easy_data(data, N):\n","    X, y = data.iloc[:,:-1], data.iloc[:, -1:]\n","    print('Original dataset shape %s' % Counter(y))\n","    data_df = pd.concat([X, y], axis=1)\n","\n","    enn = EditedNearestNeighbours(sampling_strategy='auto', n_neighbors=N, kind_sel='all', n_jobs=-1)\n","    X_res, y_res = enn.fit_resample(X, y)\n","\n","    X_res = pd.DataFrame(X_res)\n","    y_res = pd.DataFrame(y_res)\n","\n","    X_res = X_res.reset_index()\n","    y_res = y_res.reset_index()\n","\n","    easy_df = pd.concat([X_res, y_res], axis=1)\n","    easy_df = easy_df.drop(['index'], axis=1)\n","    print('easy samples %s' % Counter(easy_df.iloc[:,-1]))\n","\n","    difficult_df = easy_df.append(data_df)\n","    difficult_df = easy_df.append(data_df)\n","    difficult_df = difficult_df.drop_duplicates(keep=False)\n","    print('difficult samples %s' % Counter(difficult_df.iloc[:,-1:]))\n","    return difficult_df, easy_df\n","\n","def compress_data(data, majority_cls_dict, N):\n","    X, y = data.iloc[:,:-1], data.iloc[:,-1:]\n","    \n","    for key in majority_cls_dict:\n","        majority_cls_dict[key] = majority_cls_dict[key]/N\n","\n","    cc = ClusterCentroids(sampling_strategy=majority_cls_dict, random_state=None, estimator=None, voting='auto', n_jobs='deprecated')\n","\n","    X_res, y_res = cc.fit_resample(X, y)\n","\n","    X_res = pd.DataFrame(X_res)\n","    y_res = pd.DataFrame(y_res)\n","\n","    X_res = X_res.reset_index()\n","    y_res = y_res.reset_index()\n","\n","    compress_df = pd.concat([X_res, y_res], axis=1)\n","    compress_df = compress_df.drop(['index'], axis=1)\n","\n","    print('Cluster Centroids samples %s' % Counter(compress_df.iloc[:,-1]))\n","    return compress_df\n","\n","def synthetic_one_cls_data(data, N, multiple):    \n","    weight_list = [] \n","    n = N  \n","\n","    # weight list\n","    for x in range(n, (int(multiple/2))+n):\n","        weight1 = 1 + (1/x)\n","        weight2 = 1 - (1/x)\n","        weight_list.append(weight1)\n","        weight_list.append(weight2)\n","        weight_list.sort()\n","    \n","    # synthete samples\n","    synthetic_data = pd.DataFrame()\n","    for weight in weight_list:\n","        '''\n","        [0.25, 0.75] scale factor\n","        '''\n","        data_sample = data.iloc[:,:-1].sample(n=random.randint(int(len(data.columns)*0.25), int(len(data.columns)*0.75)), random_state=None, axis=1)*(weight)\n","        data[data_sample.columns] = data_sample\n","        synthetic_data = synthetic_data.append(data, ignore_index=True)\n","\n","    print('synthete samples %s' % Counter(synthetic_data.iloc[:,-1]))\n","    return synthetic_data\n","\n","def aug_data(easy_data, synthetic_data):\n","    return pd.concat([easy_data, synthetic_data], axis=0, ignore_index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uM19lGgO98dq"},"source":["# step 0): set [threshold], [scale factor]\n","threshold=0.01\n","n = 5\n","\n","# step 1): get minority_cls and majority_cls \n","majority_cls_dict, minority_cls_dict = class_attribute(data_df, threshold=threshold,N=n)\n","\n","# step 2): get difficult and easy samples\n","difficult_data, easy_data = get_difficult_easy_data(data_df,N=n)\n","\n","# step 3): compress difficult samples\n","compress_data = compress_data(data, majority_cls_dict, n)\n","\n","# step 4): synthetic difficult samples\n","for key in minority_cls_dict:\n","   multiple = minority_cls_dict[key]/n\n","   s_data = difficult_data[difficult_data[' label']==key] \n","   synthetic_data=synthetic_one_cls_data(s_data, N=n, multiple=multiple)\n","   synthetic_data.apped(synthetic_data, ignore_index=True)\n","\n","synthetic_data = synthetic_data.drop_duplicates(keep='last')\n","\n","# step 5): merge samples\n","merge_dta = aug_data(easy_data, compress_data, synthetic_data)\n","\n","df_shuffle = shuffle(merge_dta)\n","\n","print(\"training set augment\")\n","print(df_shuffle['Label'].value_counts())\n","x_train = df_shuffle.iloc[:,:-1]\n","y_train = df_shuffle.iloc[:,-1]\n","\n","scaler = preprocessing.MinMaxScaler().fit(x_train)\n","\n","x_train = pd.DataFrame(scaler.transform(x_train), columns=x_train.columns)\n","y_train = pd.DataFrame(y_train)\n","\n","x_test = test_df.iloc[:,:-1]\n","y_test = test_df.iloc[:,-1]\n","x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)\n","y_test = pd.DataFrame(y_test)\n","\n","x_train.to_pickle('/content/drive/My Drive/Colab Notebooks/IDS/CIC-IDS2018/pkl/dsste_x_train.pkl')\n","y_train.to_pickle('/content/drive/My Drive/Colab Notebooks/IDS/CIC-IDS2018/pkl/dsste_y_train.pkl')\n","x_test.to_pickle('/content/drive/My Drive/Colab Notebooks/IDS/CIC-IDS2018/pkl/dsste_x_test.pkl')\n","y_test.to_pickle('/content/drive/My Drive/Colab Notebooks/IDS/CIC-IDS2018/pkl/dsste_y_test.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"niw5YhjAr-JC"},"source":[""],"execution_count":null,"outputs":[]}]}